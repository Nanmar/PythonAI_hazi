# A teljes kód:

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

# A CNN struktúrájának megadása:
# Mivel az adatsetemen két féle opció lehet (jármű vagy nem jármű), ezért num_class=2
class WannabeCNNmodel(nn.Module):
    def __init__(self, num_classes=2):
        super(WannabeCNNmodel, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(64*256, 128)
        self.relu3 = nn.ReLU()
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.pool1(x)

        x = self.conv2(x)
        x = self.relu2(x)
        x = self.pool2(x)

        x = self.flatten(x)
        x = self.fc1(x)
        x = self.relu3(x)
        x = self.fc2(x)

        return x

torch.manual_seed(42)

# Az adatsetem alapból 64x64-es képek, viszont a biztonság kedvéért körbevágom, valamint az egyszerűsítés miatt szürke-árnyalatúvá alakítom (az utóbbi miatt elég egy csatorna)
transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.Grayscale(),
    transforms.ToTensor(),
])


# Az adatset elérésének útja:
# Én a saját Google fiókom drive-jára tettem fel a képeket, ezért majd a futtatáskor át kell írnod szerintem az elérési utat
# (érzékeny lehet a per-jel irányára)
local_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/PythonAI_dataset', transform=transform)

# A datasetet 80-10-10 arányban osztom fel tanító, validáló és tesztelő csoportokra
train_size = int(0.8 * len(local_dataset))
val_size=int(0.1*len(local_dataset))
test_size = len(local_dataset)-train_size-val_size


train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(local_dataset, [train_size, val_size, test_size])

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

num_classes = len(local_dataset.classes)
model = WannabeCNNmodel(num_classes=num_classes)

# "veszteségi" függvénynek CrossEntropy-t használtam mert képfelismerés feladatoknál többek között ezt ajánlotta a szakirodalom
loss_fn = nn.CrossEntropyLoss()
# az "opimalizációs" függvénynek hasonló elgondolás alapján döntöttem
opt_fn = torch.optim.SGD(model.parameters(),lr=0.1)

# Az epoch számát 15-nek veszem, mert tapasztalat alapján innentől kezd a modell overfit lenni, kezd a pontossága csökkeni
num_epochs = 15
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model.to(device)
for epoch in range(num_epochs):
    # modell tanítása:
    model.train()
    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        opt_fn.zero_grad()
        outputs = model(images) 
        loss = loss_fn(outputs, labels)
        loss.backward()
        opt_fn.step()

    # modell validálása
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)

            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = correct / total
    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}, Validation Accuracy: {100 * accuracy:.2f}%')
    print(f'Correct:{correct}')
    print(f'Total:{total}')


torch.save(model.state_dict(), 'WannabeCNNmodel.pth')


correct, total = 0, 0
with torch.no_grad():
  for images, labels in test_loader:
    images, labels = images.to(device), labels.to(device)
    outputs = model(images)
    _, predicted = torch.max(outputs, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()

accuracy = correct / total
print(f'---Test Accuracy: {100 * accuracy:.2f}%---')
